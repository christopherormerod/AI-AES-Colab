{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMKsMgRpbcYzg2DtNyLNk0T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christopherormerod/AI-AES-Colab/blob/main/FullExample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "k-yOVj2Lf-2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data_id = \"llm-aes/asap-7-original\"\n",
        "data = datasets.load_dataset(data_id)\n",
        "df = pd.DataFrame(data[\"train\"])\n",
        "train, test = sklearn.model_selection.train_test_split(df, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "NojJiMKqdZci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def aes_metrics(y1, y2):\n",
        "  qwk = sklearn.metrics.cohen_kappa_score(y1, y2, weights=\"quadratic\")\n",
        "  acc = sklearn.metrics.accuracy_score(y1, y2)\n",
        "  smd_numerator = np.mean(y1) - np.mean(y2)\n",
        "  smd_denominator = np.sqrt((np.std(y1)**2 + np.std(y2)**2)/2)\n",
        "  smd = smd_numerator / smd_denominator\n",
        "  return {\"QWK\": qwk, \"Acc\": acc, \"SMD\":smd}"
      ],
      "metadata": {
        "id": "d7a60KRldXcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUmWDvkhdQfq"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer  # For loading pre-trained models and tokenizers\n",
        "import torch  # PyTorch library for tensors and neural networks\n",
        "from tqdm.notebook import tqdm, trange  # For displaying progress bars\n",
        "\n",
        "class FineTunedEssayScorer:\n",
        "    \"\"\"\n",
        "    A class to fine-tune and use a transformer model for automated essay scoring.\n",
        "\n",
        "    This class wraps the process of loading a pre-trained model, fine-tuning it\n",
        "    on a specific essay scoring task (as a classification problem), and using it\n",
        "    for inference (scoring new essays).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_id, max_score, min_score):\n",
        "        \"\"\"\n",
        "        Initializes the essay scorer.\n",
        "\n",
        "        Args:\n",
        "            model_id (str): The identifier of the pre-trained model from the Hugging Face Hub (e.g., \"bert-base-uncased\").\n",
        "            max_score (int): The maximum possible score for the essays (e.g., 6).\n",
        "            min_score (int): The minimum possible score for the essays (e.g., 1).\n",
        "        \"\"\"\n",
        "        self.max_score = max_score\n",
        "        self.min_score = min_score\n",
        "\n",
        "        # Calculate the number of distinct score points (labels)\n",
        "        num_labels = max_score - min_score + 1\n",
        "\n",
        "        # Load the pre-trained sequence classification model with the correct number of output labels\n",
        "        self.classifier = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=num_labels)\n",
        "\n",
        "        # Load the corresponding tokenizer for the pre-trained model\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "        # Check if a GPU is available and move the model to the GPU if so\n",
        "        if torch.cuda.is_available():\n",
        "            self.classifier.cuda()\n",
        "\n",
        "    def train(self, X, y, epochs=10, dev_size=0.15):\n",
        "        \"\"\"\n",
        "        Fine-tunes the model on the provided training data.\n",
        "\n",
        "        Note: This implementation uses a batch size of 1, which is highly inefficient.\n",
        "        Consider modifying this to process data in batches for faster training.\n",
        "\n",
        "        Args:\n",
        "            X (list[str]): A list of all essay texts (strings).\n",
        "            y (list[int]): A list of all corresponding integer scores.\n",
        "            epochs (int, optional): The number of training epochs. Defaults to 10.\n",
        "            dev_size (float, optional): The proportion of the dataset to use as a validation (dev) set. Defaults to 0.15.\n",
        "        \"\"\"\n",
        "\n",
        "        # --- MODIFICATION: Split data into training and validation (dev) sets ---\n",
        "        X_train, X_dev, y_train, y_dev = train_test_split(\n",
        "            X, y, test_size=dev_size, random_state=42  # random_state for reproducibility\n",
        "        )\n",
        "\n",
        "        print(f\"Total samples: {len(X)}, Training samples: {len(X_train)}, Validation samples: {len(X_dev)}\")\n",
        "\n",
        "        # Set the model to training mode (enables dropout, etc.)\n",
        "        self.classifier.train()\n",
        "\n",
        "        # Initialize the AdamW optimizer (common for transformers)\n",
        "        optimizer = torch.optim.AdamW(self.classifier.parameters(), lr=5e-5)\n",
        "\n",
        "        N = len(X_train)  # Total number of training samples\n",
        "\n",
        "        # --- BUG FIX: Scheduler total_iters should be total steps ---\n",
        "        # Initialize a learning rate scheduler to decay the LR over time\n",
        "        scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.0, total_iters=epochs * N)\n",
        "\n",
        "        # Store the initial model state as the \"best\" state\n",
        "        best_state = self.classifier.state_dict()\n",
        "        best_score = -1  # Initialize best QWK score\n",
        "\n",
        "        print(f\"Starting training for {epochs} epochs...\")\n",
        "        for e in range(epochs):\n",
        "            # Loop over each training sample individually (batch size = 1)\n",
        "            # --- MODIFICATION: Use X_train, y_train ---\n",
        "            for i in tqdm(range(N), desc=f\"Epoch {e+1}/{epochs}\"):\n",
        "                # Clear previous gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Tokenize the current training essay text\n",
        "                X_batch = self.tokenizer(X_train[i], # Use X_train\n",
        "                                         return_tensors='pt',\n",
        "                                         padding=\"max_length\",\n",
        "                                         truncation=True,\n",
        "                                         max_length=512).to(self.classifier.device)\n",
        "\n",
        "                # Adjust the label to be zero-indexed (e.g., score 1 -> label 0)\n",
        "                y_batch = y_train[i] - self.min_score # Use y_train\n",
        "\n",
        "                # Perform a forward pass and compute the loss\n",
        "                outputs = self.classifier(**X_batch, labels=torch.tensor([y_batch]).to(self.classifier.device))\n",
        "\n",
        "                # Get the loss\n",
        "                loss = outputs.loss\n",
        "\n",
        "                # Clip gradients to prevent exploding gradients\n",
        "                torch.nn.utils.clip_grad_norm_(self.classifier.parameters(), 1.0)\n",
        "\n",
        "                # Perform a backward pass to compute gradients\n",
        "                loss.backward()\n",
        "\n",
        "                # Update model parameters\n",
        "                optimizer.step()\n",
        "\n",
        "                # Update the learning rate\n",
        "                scheduler.step()\n",
        "\n",
        "            print(\"Evaluating model on dev set...\")\n",
        "            metrics = self.evaluate(X_dev, y_dev) # Changed from (X, y) to (X_dev, y_dev)\n",
        "\n",
        "            print(f\"Epoch {e+1} Validation Metrics: {metrics}\")\n",
        "\n",
        "            # Check if the current model is the best one based on QWK\n",
        "            if metrics[\"QWK\"] > best_score:\n",
        "                print(f\"New best score: {metrics['QWK']:.4f}\")\n",
        "                self.best_state = self.classifier.state_dict()  # Save the model's weights\n",
        "                best_score = metrics[\"QWK\"]\n",
        "\n",
        "        # After all epochs, load the weights of the best-performing model\n",
        "        print(f\"Training complete. Loading best model state with QWK: {best_score:.4f}\")\n",
        "        self.classifier.load_state_dict(self.best_state)\n",
        "\n",
        "    def evaluate(self, X, y):\n",
        "        \"\"\"\n",
        "        Evaluates the model on a given dataset.\n",
        "\n",
        "        Args:\n",
        "            X (list[str]): A list of essay texts.\n",
        "            y (list[int]): A list of corresponding true scores.\n",
        "\n",
        "        Returns:\n",
        "            dict: A dictionary of evaluation metrics (e.g., {\"QWK\": 0.85}).\n",
        "        \"\"\"\n",
        "        # Set the model to evaluation mode (disables dropout, etc.)\n",
        "        self.classifier.eval()\n",
        "\n",
        "        # Get the model's predicted scores for the essays\n",
        "        scores = self.score(X)\n",
        "\n",
        "        # Compute and return metrics (assumes 'aes_metrics' function is defined)\n",
        "        return aes_metrics(y, scores)\n",
        "\n",
        "    def score(self, X):\n",
        "        \"\"\"\n",
        "        Generates scores for a list of new essays (inference).\n",
        "\n",
        "        Args:\n",
        "            X (list[str]): A list of essay texts to score.\n",
        "\n",
        "        Returns:\n",
        "            list[int]: A list of predicted integer scores.\n",
        "        \"\"\"\n",
        "        # Set the model to evaluation mode\n",
        "        self.classifier.eval()\n",
        "\n",
        "        scores = []  # List to hold the predicted scores\n",
        "\n",
        "        # Disable gradient calculations to save memory and computation\n",
        "        with torch.no_grad():\n",
        "            # Process each essay one by one\n",
        "            for X_batch in tqdm(X, desc=\"Scoring\"):\n",
        "                # Tokenize the essay\n",
        "                X_batch = self.tokenizer(X_batch,\n",
        "                                         return_tensors='pt',\n",
        "                                         padding=\"max_length\",\n",
        "                                         truncation=True,\n",
        "                                         max_length=512).to(self.classifier.device)\n",
        "\n",
        "                # Perform a forward pass (inference)\n",
        "                outputs = self.classifier(**X_batch)\n",
        "\n",
        "                # Get the raw output logits (scores for each class)\n",
        "                predicted_label = int(outputs.logits.cpu().argmax(dim=1))\n",
        "\n",
        "                # Convert the zero-indexed label back to the original score\n",
        "                predicted_score = predicted_label + self.min_score\n",
        "\n",
        "                scores.append(predicted_score)\n",
        "\n",
        "        return scores\n",
        "\n",
        "    def save(self, path):\n",
        "        \"\"\"\n",
        "        Saves the fine-tuned model and tokenizer to a directory.\n",
        "\n",
        "        Args:\n",
        "            path (str): The directory path to save the model and tokenizer.\n",
        "        \"\"\"\n",
        "        print(f\"Saving model and tokenizer to {path}\")\n",
        "        # Save the model's weights and configuration\n",
        "        self.classifier.save_pretrained(path)\n",
        "        # Save the tokenizer's vocabulary and configuration\n",
        "        self.tokenizer.save_pretrained(path)\n",
        "\n",
        "    def load(self, path):\n",
        "        \"\"\"\n",
        "        Loads a fine-tuned model and tokenizer from a directory.\n",
        "\n",
        "        Args:\n",
        "            path (str): The directory path to load from.\n",
        "        \"\"\"\n",
        "        print(f\"Loading model and tokenizer from {path}\")\n",
        "        # Load the saved model\n",
        "        self.classifier = AutoModelForSequenceClassification.from_pretrained(path)\n",
        "        # Load the saved tokenizer\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(path)\n",
        "\n",
        "        # Move the loaded model to the GPU if available\n",
        "        if torch.cuda.is_available():\n",
        "            self.classifier.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Pete = FineTunedEssayScorer(\"google/electra-small-discriminator\", max_score = max(train['rater1_domain1']), min_score = min(train['rater1_domain1']))\n",
        "Pete.train(list(train['essay']), list(train['rater1_domain1']), epochs=4)"
      ],
      "metadata": {
        "id": "vwqV5iUCgBQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IRoF-ft1gq1g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}